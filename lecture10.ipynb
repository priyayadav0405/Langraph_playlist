{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba2e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad301ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages : Annotated[list[BaseMessage], add_messages] #we will keep adding messages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "api_key=''\n",
    "llm = ChatGroq(model='llama-3.1-8b-instant',api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd3c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state : ChatState)->ChatState:\n",
    "    messages = state['messages']\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {'messages' :[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f2cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node',chat_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "chatbot = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c7ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    'messages' :[HumanMessage(content='What is the capital of India')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15fafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1081a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user :  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_message = input('Type here: ')\n",
    "\n",
    "    print('user : ',user_message)\n",
    "\n",
    "    if user_message.strip().lower() in ['exit','quit','bye']:\n",
    "        break\n",
    "\n",
    "    response = chatbot.invoke({'messages' : [HumanMessage(content = user_message)]})\n",
    "\n",
    "    print('AI' , response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef93262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f08daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer =MemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node' , chat_node)\n",
    "\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4790203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User message  hey ,my name is priya\n",
      "AI :  Nice to meet you, Priya. Is there something I can help you with or would you like to chat?\n",
      "User message  can you plz tell my name\n",
      "AI :  Your name is Priya.\n",
      "User message  how did you know\n",
      "AI :  You told me earlier, when you introduced yourself by saying \"hey, my name is Priya\".\n",
      "User message  so, will you save all info that i give you\n",
      "AI :  For our conversation, I have a limited ability to remember context and previous messages. However, I don't retain any information about your identity or personal data once our conversation is closed.\n",
      "\n",
      "Each time you interact with me, it's a new conversation, and I start from a clean slate. I use natural language processing to understand and respond to your input in real-time, but I don't store any data about you or our conversation.\n",
      "\n",
      "If you want to share sensitive information or have a follow-up conversation, feel free to share it again, and I'll do my best to help!\n",
      "User message  exit\n"
     ]
    }
   ],
   "source": [
    "thread_id ='1'\n",
    "\n",
    "while True:\n",
    "    user_message = input('Type here: ')\n",
    "    print('User message ',user_message)\n",
    "\n",
    "    if user_message.strip().lower() in ['exit','quit','bye']:\n",
    "        break\n",
    "    config = {'configurable' : {'thread_id' : thread_id}}\n",
    "\n",
    "    response = chatbot.invoke({'messages' : [HumanMessage(content=user_message)]} , config=config)\n",
    "\n",
    "    print('AI : ',response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "398bf2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='hey ,my name is priya', additional_kwargs={}, response_metadata={}, id='e394fd37-1a29-4601-8f88-c51b6ec14146'), AIMessage(content='Nice to meet you, Priya. Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 42, 'total_tokens': 66, 'completion_time': 0.037516665, 'completion_tokens_details': None, 'prompt_time': 0.002454867, 'prompt_tokens_details': None, 'queue_time': 0.055624118, 'total_time': 0.039971532}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb5c4-0b7c-70f1-97ed-308f8af9a77e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 42, 'output_tokens': 24, 'total_tokens': 66}), HumanMessage(content='can you plz tell my name', additional_kwargs={}, response_metadata={}, id='2dca7755-cd92-4adc-9a1a-ee94b8375a7c'), AIMessage(content='Your name is Priya.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 82, 'total_tokens': 89, 'completion_time': 0.010385525, 'completion_tokens_details': None, 'prompt_time': 0.004778925, 'prompt_tokens_details': None, 'queue_time': 0.060203344, 'total_time': 0.01516445}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb5c4-3203-7153-a77a-f333704b403a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 82, 'output_tokens': 7, 'total_tokens': 89}), HumanMessage(content='how did you know', additional_kwargs={}, response_metadata={}, id='d69ee5e4-0f75-4c74-a3b0-4497a767a79a'), AIMessage(content='You told me earlier, when you introduced yourself by saying \"hey, my name is Priya\".', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 102, 'total_tokens': 123, 'completion_time': 0.040956814, 'completion_tokens_details': None, 'prompt_time': 0.008508256, 'prompt_tokens_details': None, 'queue_time': 0.052152674, 'total_time': 0.04946507}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb5c4-4f92-7762-af09-d968bd0d2793-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 102, 'output_tokens': 21, 'total_tokens': 123}), HumanMessage(content='so, will you save all info that i give you', additional_kwargs={}, response_metadata={}, id='03d2b62f-09e7-4e13-bb2c-0673b663d1a7'), AIMessage(content=\"For our conversation, I have a limited ability to remember context and previous messages. However, I don't retain any information about your identity or personal data once our conversation is closed.\\n\\nEach time you interact with me, it's a new conversation, and I start from a clean slate. I use natural language processing to understand and respond to your input in real-time, but I don't store any data about you or our conversation.\\n\\nIf you want to share sensitive information or have a follow-up conversation, feel free to share it again, and I'll do my best to help!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 143, 'total_tokens': 260, 'completion_time': 0.23670059, 'completion_tokens_details': None, 'prompt_time': 0.010467421, 'prompt_tokens_details': None, 'queue_time': 0.116342119, 'total_time': 0.247168011}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb5c4-8ebd-7070-9ff1-398837f0682f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 143, 'output_tokens': 117, 'total_tokens': 260})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f03e6-1cbd-654e-800a-b2ada2afbae2'}}, metadata={'source': 'loop', 'step': 10, 'parents': {}}, created_at='2026-01-13T05:11:56.787233+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f03e6-188e-6000-8009-4d121018f854'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if config was different ,it will be in different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb7ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637a69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
