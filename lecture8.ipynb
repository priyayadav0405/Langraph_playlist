{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3512f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph  import START, END,StateGraph\n",
    "from typing import TypedDict,Annotated,List,Tuple\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc43083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6271cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "api_key=\n",
    "llm = ChatGroq(model='llama-3.1-8b-instant',api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2faf0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke_agent(TypedDict):\n",
    "    topic :str\n",
    "    joke:str\n",
    "    explaination: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6507a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joke(state : Joke_agent) -> Joke_agent:\n",
    "    prompt = f'Generate a joke ,it should be funny on the topic :{state['topic']}'\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "649b5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explanation(state : Joke_agent) ->Joke_agent:\n",
    "    prompt = f'Generate the explaination of this joke {state[\"joke\"]}.'\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {'explaination' : response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f05ac21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x13fb635a330>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(Joke_agent)\n",
    "graph.add_node('create_joke_node',create_joke)\n",
    "graph.add_node('create_explanation_node',create_explanation)\n",
    "\n",
    "graph.add_edge(START,'create_joke_node')\n",
    "graph.add_edge('create_joke_node','create_explanation_node')\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "graph.add_edge('create_explanation_node',END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "685657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.invoke({'topic':'bhindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7525f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\" : {\"thread_id\" : \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "277dceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'samosa',\n",
       " 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}),\n",
       " 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke({'topic':'samosa'} , config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd427f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-c348-61e1-8002-5b088a4e20e7'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T15:39:00.781513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11775183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-c348-61e1-8002-5b088a4e20e7'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T15:39:00.781513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}, next=('create_explanation_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-10T15:38:59.991883+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, tasks=(PregelTask(id='f6e8af01-9f67-0f03-cfce-6082f76f4980', name='create_explanation_node', path=('__pregel_pull', 'create_explanation_node'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('create_joke_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-10T15:38:59.441771+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, tasks=(PregelTask(id='a95f8224-46e5-30d9-67af-8a3120d610c5', name='create_joke_node', path=('__pregel_pull', 'create_joke_node'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-10T15:38:59.432218+00:00', parent_config=None, tasks=(PregelTask(id='4fcf3f9b-88b4-01a7-16ca-a4b1b5e9b402', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'samosa'}),), interrupts=())]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61963874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58cfd88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c92583f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pasta',\n",
       " 'joke': AIMessage(content='A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and pasta?\"\\n\\nThe librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s a first course or a main course.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 49, 'total_tokens': 101, 'completion_time': 0.065259127, 'completion_tokens_details': None, 'prompt_time': 0.002385068, 'prompt_tokens_details': None, 'queue_time': 0.055411642, 'total_time': 0.067644195}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-9880-7711-946a-1b9da76fe376-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 49, 'output_tokens': 52, 'total_tokens': 101}),\n",
       " 'explaination': AIMessage(content='**Pavlov\\'s Dogs and Pasta Joke Explanation**\\n\\nThe joke begins with a man entering a library and asking the librarian for books on Pavlov\\'s dogs and pasta. Pavlov\\'s dogs refer to the famous experiment conducted by Ivan Pavlov, where he conditioned dogs to salivate at the sound of a bell, associating it with food.\\n\\nThe punchline lies in the librarian\\'s response: \"It rings a bell, but I\\'m not sure if it\\'s a first course or a main course.\" Here\\'s what makes it funny:\\n\\n1. **Wordplay**: The phrase \"rings a bell\" has a double meaning. In the context of Pavlov\\'s experiment, the sound of a bell was used to trigger salivation in dogs. However, \"rings a bell\" is also an idiom that means something seems familiar or reminds us of something. The librarian is making a clever connection between the two meanings.\\n2. **Food pun**: The librarian\\'s response also includes a food pun, comparing the hypothetical book to a \"first course\" or \"main course\" of a meal. This adds a playful touch to the joke, as it references the context of pasta.\\n3. **Playful misdirection**: The librarian\\'s response initially seems to be a serious answer to the man\\'s question, but it quickly takes an unexpected turn with the food pun. This playful misdirection creates surprise and delight, making the joke more enjoyable.\\n\\nOverall, the joke relies on a combination of wordplay, clever references, and playful misdirection to create a humorous effect.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 311, 'total_tokens': 628, 'completion_time': 0.558534178, 'completion_tokens_details': None, 'prompt_time': 0.102036005, 'prompt_tokens_details': None, 'queue_time': 0.055656714, 'total_time': 0.660570183}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-9996-7a11-ae4d-97edd792bb17-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 311, 'output_tokens': 317, 'total_tokens': 628})}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 ={\"configurable\" : {\"thread_id\" : \"2\"}}\n",
    "workflow.invoke({'topic' : 'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83de4227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-c348-61e1-8002-5b088a4e20e7'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T15:39:00.781513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00799d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-c348-61e1-8002-5b088a4e20e7'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T15:39:00.781513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}, next=('create_explanation_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-10T15:38:59.991883+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, tasks=(PregelTask(id='f6e8af01-9f67-0f03-cfce-6082f76f4980', name='create_explanation_node', path=('__pregel_pull', 'create_explanation_node'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('create_joke_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-10T15:38:59.441771+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, tasks=(PregelTask(id='a95f8224-46e5-30d9-67af-8a3120d610c5', name='create_joke_node', path=('__pregel_pull', 'create_joke_node'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-10T15:38:59.432218+00:00', parent_config=None, tasks=(PregelTask(id='4fcf3f9b-88b4-01a7-16ca-a4b1b5e9b402', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'samosa'}),), interrupts=())]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a82b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96eb0ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f0ee2d5-dd72-6e56-bfff-69dad3c33eb3'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\" : {\"thread_id\" : \"1\", \"checkpoint_id\":\"1f0ee2d5-dd72-6e56-bfff-69dad3c33eb3\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39a848",
   "metadata": {},
   "source": [
    "#Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0363c222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f0ee326-5896-6c49-bfff-5bc6619dbce'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\" : {\"thread_id\" : \"1\" , \"checkpoint_id\":\"1f0ee326-5896-6c49-bfff-5bc6619dbce\"}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb06486f",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoint_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1f0ee326-5896-6c49-bfff-5bc6619dbce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:2579\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2576\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2577\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2579\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2580\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2608\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1122\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:725\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys, updated_channels)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None,{\"configurable\" : {\"thread_id\" : \"1\", \"checkpoint_id\":\"1f0ee326-5896-6c49-bfff-5bc6619dbce\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b218087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.031239432, 'completion_tokens_details': None, 'prompt_time': 0.002359737, 'prompt_tokens_details': None, 'queue_time': 0.055059312, 'total_time': 0.033599169}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba85a-92f3-7623-b94f-bc29928c149e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Joke Explanation:**\\n\\nThe joke revolves around a play on words and a clever use of puns. The setup, \"Why did the samosa go to therapy?\", is a typical format for a joke where the punchline is expected to be a clever or unexpected reason why the subject (samosa) went to therapy.\\n\\nThe punchline, \"Because it was feeling crumby and had a lot of folded emotions,\" is where the joke relies on wordplay. Here\\'s a breakdown of the puns:\\n\\n1. **\"Crumby\"**: A samosa is a type of Indian fried or baked pastry that is typically crispy and flaky on the outside, but soft and crumbly on the inside. When the joke says the samosa was \"feeling crumby,\" it\\'s using a common phrase to describe feeling down or unwell, but also referencing the physical texture of the samosa.\\n2. **\"Folded emotions\"**: A samosa is a pastry that is folded and sealed to create its shape. The joke is saying that the samosa has \"folded emotions,\" which is a play on words referencing both the physical act of folding the pastry and the idea of having emotions that are complex or layered.\\n\\nThe joke relies on the listener being familiar with the concept of a samosa and its texture, as well as understanding the double meaning of the word \"folded.\" The punchline is a clever play on words that creates a humorous connection between the setup and the reason why the samosa went to therapy.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 315, 'prompt_tokens': 281, 'total_tokens': 596, 'completion_time': 0.488691766, 'completion_tokens_details': None, 'prompt_time': 0.016707012, 'prompt_tokens_details': None, 'queue_time': 0.049882747, 'total_time': 0.505398778}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba85a-9496-70c0-8792-7cb8b675ca3b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 315, 'total_tokens': 596})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-6365-601a-8002-14373db6ced0'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T14:41:07.909634+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-5cd2-63b0-8001-2a8bb76d9134'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.031239432, 'completion_tokens_details': None, 'prompt_time': 0.002359737, 'prompt_tokens_details': None, 'queue_time': 0.055059312, 'total_time': 0.033599169}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba85a-92f3-7623-b94f-bc29928c149e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}, next=('create_explanation_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-5cd2-63b0-8001-2a8bb76d9134'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-10T14:41:07.220369+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-58be-6f0f-8000-73ef4a4a33f6'}}, tasks=(PregelTask(id='184d5e4c-195e-a5da-755e-ae3799eec882', name='create_explanation_node', path=('__pregel_pull', 'create_explanation_node'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Joke Explanation:**\\n\\nThe joke revolves around a play on words and a clever use of puns. The setup, \"Why did the samosa go to therapy?\", is a typical format for a joke where the punchline is expected to be a clever or unexpected reason why the subject (samosa) went to therapy.\\n\\nThe punchline, \"Because it was feeling crumby and had a lot of folded emotions,\" is where the joke relies on wordplay. Here\\'s a breakdown of the puns:\\n\\n1. **\"Crumby\"**: A samosa is a type of Indian fried or baked pastry that is typically crispy and flaky on the outside, but soft and crumbly on the inside. When the joke says the samosa was \"feeling crumby,\" it\\'s using a common phrase to describe feeling down or unwell, but also referencing the physical texture of the samosa.\\n2. **\"Folded emotions\"**: A samosa is a pastry that is folded and sealed to create its shape. The joke is saying that the samosa has \"folded emotions,\" which is a play on words referencing both the physical act of folding the pastry and the idea of having emotions that are complex or layered.\\n\\nThe joke relies on the listener being familiar with the concept of a samosa and its texture, as well as understanding the double meaning of the word \"folded.\" The punchline is a clever play on words that creates a humorous connection between the setup and the reason why the samosa went to therapy.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 315, 'prompt_tokens': 281, 'total_tokens': 596, 'completion_time': 0.488691766, 'completion_tokens_details': None, 'prompt_time': 0.016707012, 'prompt_tokens_details': None, 'queue_time': 0.049882747, 'total_time': 0.505398778}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba85a-9496-70c0-8792-7cb8b675ca3b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 315, 'total_tokens': 596})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('create_joke_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-58be-6f0f-8000-73ef4a4a33f6'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-10T14:41:06.793038+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-5896-6c49-bfff-5bc6619dbce4'}}, tasks=(PregelTask(id='448fd61e-9fa8-2039-d1bd-9c268afd72be', name='create_joke_node', path=('__pregel_pull', 'create_joke_node'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.031239432, 'completion_tokens_details': None, 'prompt_time': 0.002359737, 'prompt_tokens_details': None, 'queue_time': 0.055059312, 'total_time': 0.033599169}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba85a-92f3-7623-b94f-bc29928c149e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee326-5896-6c49-bfff-5bc6619dbce4'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-10T14:41:06.776583+00:00', parent_config=None, tasks=(PregelTask(id='cbef5755-aa6e-3b3d-d6e3-6635e8b9fc95', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'samosa'}),), interrupts=())]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e53356",
   "metadata": {},
   "source": [
    "#Updating State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9f75110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ee3a8-4dab-6687-8000-ab14da99f546'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({\"configurable\" : {\"thread_id\" : \"1\" , \"checkpoint_id\":\"1f0ee2d5-dd72-6e56-bfff-69dad3c33eb3\" , \"checkpoint_ns\":\"\"}} , {'topic':'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02618a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('create_joke_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a8-4dab-6687-8000-ab14da99f546'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2026-01-10T15:39:15.292531+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee2d5-dd72-6e56-bfff-69dad3c33eb3'}}, tasks=(PregelTask(id='c0b24be4-bf75-9fdd-daa9-a8e940ffffc7', name='create_joke_node', path=('__pregel_pull', 'create_joke_node'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76}), 'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-c348-61e1-8002-5b088a4e20e7'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-10T15:39:00.781513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}, next=('create_explanation_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-bbc0-64ee-8001-7e177ab54313'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-10T15:38:59.991883+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, tasks=(PregelTask(id='f6e8af01-9f67-0f03-cfce-6082f76f4980', name='create_explanation_node', path=('__pregel_pull', 'create_explanation_node'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Samosa Therapy Joke Explanation**\\n\\nThe joke \"Why did the samosa go to therapy? Because it was feeling crumby and had a lot of folded emotions\" is a play on words that combines a common phrase with the characteristics of a samosa.\\n\\n**Breaking down the joke:**\\n\\n1. **\"Why did the samosa go to therapy?\"**: This is the setup for the joke, asking the listener to imagine a situation where a samosa (a type of Indian snack) is seeking therapy.\\n2. **\"Because it was feeling crumby\"**: This is the punchline, which is a pun on the phrase \"feeling crumby,\" meaning feeling unwell or in a bad mood. However, a samosa is also a pastry that is often crumbly in texture, so the phrase takes on a new meaning.\\n3. **\"and had a lot of folded emotions\"**: This adds another layer of wordplay, as a samosa is also a pastry that is folded into a specific shape. The phrase \"folded emotions\" is a play on the idea of emotions being complex and multifaceted, but also references the physical folding of a samosa.\\n\\n**The humor:**\\n\\nThe joke relies on a combination of wordplay and unexpected twists to create humor. The listener is initially led to expect a more serious or conventional reason for the samosa going to therapy, but the punchline subverts this expectation with a clever play on words. The joke requires a basic understanding of the characteristics of a samosa and the phrase \"feeling crumby,\" but the wordplay is clever and unexpected, making it amusing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 281, 'total_tokens': 620, 'completion_time': 0.536011794, 'completion_tokens_details': None, 'prompt_time': 0.041841932, 'prompt_tokens_details': None, 'queue_time': 0.056882487, 'total_time': 0.577853726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-921b-77f0-b4b1-d6c80f38eb05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 281, 'output_tokens': 339, 'total_tokens': 620})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('create_joke_node',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b681-6433-8000-bd69a7df4da8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-10T15:38:59.441771+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, tasks=(PregelTask(id='a95f8224-46e5-30d9-67af-8a3120d610c5', name='create_joke_node', path=('__pregel_pull', 'create_joke_node'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of folded emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 50, 'total_tokens': 76, 'completion_time': 0.035191877, 'completion_tokens_details': None, 'prompt_time': 0.045778753, 'prompt_tokens_details': None, 'queue_time': 0.083573396, 'total_time': 0.08097063}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba88f-8ff8-7641-963d-2a1810802f60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 26, 'total_tokens': 76})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ee3a7-b669-6f07-bfff-486248e4969c'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-10T15:38:59.432218+00:00', parent_config=None, tasks=(PregelTask(id='4fcf3f9b-88b4-01a7-16ca-a4b1b5e9b402', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'samosa'}),), interrupts=())]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec031c64",
   "metadata": {},
   "source": [
    "#Fault Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91cf460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abff777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fb3f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\" Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\" Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\" Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46690ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running graph: Please manually interrupt during Step 2...\n",
      " Step 1 executed\n",
      " Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     print(\" Running graph: Please manually interrupt during Step 2...\")\n",
    "#     graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\" Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8352b884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb694837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Re-running the graph to demonstrate fault tolerance...\n"
     ]
    },
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6. Re-run to show fault-tolerant resume\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Re-running the graph to demonstrate fault tolerance...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m final_state = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mthread-1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Final State:\u001b[39m\u001b[33m\"\u001b[39m, final_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:2579\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2576\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2577\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2579\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2580\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2608\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1122\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:725\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys, updated_channels)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Re-run to show fault-tolerant resume\n",
    "print(\"\\n Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "print(\"\\n Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71adb5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
